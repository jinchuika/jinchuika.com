<!DOCTYPE html>
<html lang="en">
<head>
  
    <script type="application/ld+json">
{
    "@context" : "http://schema.org",
    "@type" : "BlogPosting",
    "mainEntityOfPage": {
        "@type": "WebPage",
        "@id": "https:\/\/jinchuika.com"
    },
    "articleSection" : "post",
    "name" : "Preprocessing data for data science (Part 1)",
    "headline" : "Preprocessing data for data science (Part 1)",
    "description" : "A [study regarding data science jobs](https:\/\/visit.figure-eight.com\/rs\/416-ZBE-142\/images\/CrowdFlower_DataScienceReport_2016.pdf) showed that 60% of the time spent by data scientists consists only on cleaning and organizing data. So in order to make the most out of our time, my data science fellas, in this four-part series we\x27ll se how to preprocess data like a boss, using the Pandas Python library and the preprocessing module from scikit-learn.",
    "inLanguage" : "en",
    "author": {
        "@type": "Person",
        "name": "Luis Carlos Contreras"
    },
    "publisher": {
        "@type": "Organization",
        "name": "Luis Carlos Contreras",
        "logo": {
            "@type": "ImageObject",
            "url": "https:\/\/jinchuika.com\/img\/favicon.ico",
            "width": "80",
            "height": "80"
        }
    },
    "creator" : "Luis Carlos Contreras",
    "copyrightHolder" : "Luis Carlos Contreras",
    "copyrightYear" : "2019",
    "datePublished": "2019-03-28 22:46:51 -0600 CST",
    "dateModified" : "2019-03-28 22:46:51 -0600 CST",
    "url" : "https:\/\/jinchuika.com\/post\/1-preprocessing-part-1\/",
    "wordCount" : "1127",
    
    "image": {
        "@type": "ImageObject",
        "url": "https:\/\/jinchuika.com\/post\/1-preprocessing-part-1\/cover.jpg",
        "width": 800,
        "height": 600
    },
    
    "keywords" : [
    
    ]
}
</script>

    <title>Preprocessing data for data science (Part 1) :: Jinchuika — Developer blog</title>
  
  <meta http-equiv="content-type" content="text/html; charset=utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1">
<meta name="description" content="A study regarding data science jobs showed that 60% of the time spent by data scientists consists only on cleaning and organizing data. So in order to make the most out of our time, my data science fellas, in this four-part series we&amp;rsquo;ll se how to preprocess data like a boss, using the Pandas Python library and the preprocessing module from scikit-learn.
Pretty much everything we do in an AI algorithm are matrix operations."/>
<meta name="keywords" content="blog,technology,programming,artificial intelligence,machine learning"/>
<meta name="robots" content="noodp"/>
<link rel="canonical" href="https://jinchuika.com/post/1-preprocessing-part-1/" />





<link rel="stylesheet" href="https://jinchuika.com/assets/style.css">


<link rel="stylesheet" href="https://jinchuika.com/style.css">


<link rel="apple-touch-icon-precomposed" sizes="144x144" href="https://jinchuika.com/img/apple-touch-icon-144-precomposed.png">
<link rel="shortcut icon" href="https://jinchuika.com/img/favicon.png">


<meta name="twitter:card" content="summary_large_image"/>
<meta name="twitter:image" content="https://jinchuika.com/post/1-preprocessing-part-1/cover.jpg"/>
<meta name="twitter:title" content="Preprocessing data for data science (Part 1)"/>
<meta name="twitter:description" content="A [study regarding data science jobs](https://visit.figure-eight.com/rs/416-ZBE-142/images/CrowdFlower_DataScienceReport_2016.pdf) showed that 60% of the time spent by data scientists consists only on cleaning and organizing data. So in order to make the most out of our time, my data science fellas, in this four-part series we&#39;ll se how to preprocess data like a boss, using the Pandas Python library and the preprocessing module from scikit-learn."/>



<meta property="og:title" content="Preprocessing data for data science (Part 1)" />
<meta property="og:description" content="A [study regarding data science jobs](https://visit.figure-eight.com/rs/416-ZBE-142/images/CrowdFlower_DataScienceReport_2016.pdf) showed that 60% of the time spent by data scientists consists only on cleaning and organizing data. So in order to make the most out of our time, my data science fellas, in this four-part series we&#39;ll se how to preprocess data like a boss, using the Pandas Python library and the preprocessing module from scikit-learn." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://jinchuika.com/post/1-preprocessing-part-1/" />
<meta property="og:image" content="https://jinchuika.com/post/1-preprocessing-part-1/cover.jpg"/>
<meta property="article:published_time" content="2019-03-28T22:46:51-06:00" />
<meta property="article:modified_time" content="2019-03-28T22:46:51-06:00" /><meta property="og:site_name" content="Jinchuika" />






  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<script>
(adsbygoogle = window.adsbygoogle || []).push({
	google_ad_client: "ca-pub-7910880084570598",
	enable_page_level_ads: true
});
</script>
</head>
<body class="dark-theme">
<div class="container">
  <header class="header">
  <span class="header__inner">
    <a href="https://jinchuika.com/" class="logo" style="text-decoration: none;">
  
    <span class="logo__mark"><svg xmlns="http://www.w3.org/2000/svg" class="greater-icon" viewBox="0 0 44 44">
  <path fill="none" d="M15 8l14.729 14.382L15 35.367"/>
</svg>
</span>
    <span class="logo__text">Jinchuika</span>
    <span class="logo__cursor"></span>
  
</a>

    <span class="header__right">
      
        <nav class="menu">
  <ul class="menu__inner menu__inner--desktop">
    
      
        
          <li><a href="https://jinchuika.com/about-me">About</a></li>
        
      
        
          <li><a href="https://jinchuika.com/es">Español</a></li>
        
      
      
    
  </ul>

  <ul class="menu__inner menu__inner--mobile">
    
      
        <li><a href="https://jinchuika.com/about-me">About</a></li>
      
    
      
        <li><a href="https://jinchuika.com/es">Español</a></li>
      
    
  </ul>
</nav>

        <span class="menu-trigger">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
            <path d="M0 0h24v24H0z" fill="none"/>
            <path d="M3 18h18v-2H3v2zm0-5h18v-2H3v2zm0-7v2h18V6H3z"/>
          </svg>
        </span>
      
      <span class="theme-toggle">
        <svg class="theme-toggler" width="24" height="24" viewBox="0 0 48 48" fill="none" xmlns="http://www.w3.org/2000/svg">
  <path d="M22 41C32.4934 41 41 32.4934 41 22C41 11.5066 32.4934 3 22
  3C11.5066 3 3 11.5066 3 22C3 32.4934 11.5066 41 22 41ZM7 22C7
  13.7157 13.7157 7 22 7V37C13.7157 37 7 30.2843 7 22Z"/>
</svg>

      </span>
    </span>
  </span>
</header>


  <div class="content">
    
  
  

  <div class="post">
    <h2 class="post-title"><a href="https://jinchuika.com/post/1-preprocessing-part-1/">Preprocessing data for data science (Part 1)</a></h2>
    <div class="post-meta">
      
        <span class="post-date">
          2019-03-28
        </span>

        
          
        
      

      <span class="post-author">— Written by Luis Carlos Contreras</span>
      
        <span class="post-read-time">— 6 min read</span>
      
    </div>

    

    
      
        <img src="https://jinchuika.com/post/1-preprocessing-part-1/cover.jpg" class="post-cover" />
      
    

    <div class="post-content">
      <p>A <a href="https://visit.figure-eight.com/rs/416-ZBE-142/images/CrowdFlower_DataScienceReport_2016.pdf">study regarding data science jobs</a> showed that 60% of the time spent by data scientists consists only on cleaning and organizing data. So in order to make the most out of our time, my data science fellas, in this four-part series we&rsquo;ll se how to preprocess data like a boss, using the Pandas Python library and the preprocessing module from scikit-learn.</p>
<p>Pretty much everything we do in an AI algorithm are matrix operations. That means that every value must be represented in a numerical format and, ideally, one that optimizes the operations performance. Given that most datasets come in a very nonoptimal format, we must apply certain transformations in order to obtain the most ideal format. This process is called <strong>preprocessing</strong>.</p>
<h2 id="start-of-the-cleaning-data-process">Start of the cleaning data process</h2>
<p>For this series of examples we&rsquo;ll be using <a href="https://www.kaggle.com/karangadiya/fifa19">this interesting dataset of FIFA 19 players</a>. This game allows players to create a custom character with different values for their stats like speed, weight, height, etc. We will create an algorithm for recommending the most ideal position (striker, central back, etc.) for that character based on those values and what we&rsquo;ve learned from the rest of the football player base.</p>
<blockquote>
<p>You can find all the code for this series in the <a href="https://github.com/jinchuika/preprocessing-tutorial/blob/master/part-1.ipynb">GitHub repo</a>.</p>
</blockquote>
<p>As always, we&rsquo;ll start by loading the data and do a basic exploration of it.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#f92672">import</span> pandas <span style="color:#f92672">as</span> pd
raw_df <span style="color:#f92672">=</span> pd<span style="color:#f92672">.</span>read_csv(<span style="color:#e6db74">&#39;data.csv&#39;</span>)
<span style="color:#75715e"># raw_df.info() # display all the columns and their data type</span>
</code></pre></div><p>The very first thing to do is choosing what features could be useful for training the model. Let&rsquo;s start by discriminating what features definitely won&rsquo;t contribute and then choosing which ones could.</p>
<p>As rule of thumb, using unique non-numerical values is not useful since we want the model to generalize. So columns like <code>ID</code> and <code>Name</code> have to go. Features that are highly correlated to each other or are directly calculations don&rsquo;t need to be included twice. For example, if we store the birth date, we don&rsquo;t need to include the age since it is a result from the prior. In this case, <code>Overall</code> is the score resulting from the rest of the features, so there&rsquo;s no need to have it.</p>
<p>Knowing what features influence the outcome of the objective one is a complex task. For the sake of this post lenght, we&rsquo;ll arbitrarily pick some based on what we think impacts a player&rsquo;s skill. Once the features are selected, let&rsquo;s make a new data frame with only the colums we chose.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#75715e"># it&#39;s useful to have the columns in a list you can modify easily</span>
useful_columns <span style="color:#f92672">=</span> [
    <span style="color:#e6db74">&#39;Age&#39;</span>,
    <span style="color:#e6db74">&#39;Preferred Foot&#39;</span>,
    <span style="color:#e6db74">&#39;Height&#39;</span>,
    <span style="color:#e6db74">&#39;Weight&#39;</span>,
    <span style="color:#e6db74">&#39;Agility&#39;</span>,
    <span style="color:#e6db74">&#39;Strength&#39;</span>,
    <span style="color:#e6db74">&#39;Dribbling&#39;</span>,
    <span style="color:#e6db74">&#39;Jumping&#39;</span>,
    <span style="color:#e6db74">&#39;Marking&#39;</span>,
    <span style="color:#e6db74">&#39;Interceptions&#39;</span>,
    <span style="color:#e6db74">&#39;Position&#39;</span>, <span style="color:#75715e"># I like to let my objective columns at the end</span>
]
working_df <span style="color:#f92672">=</span> raw_df[useful_columns]
<span style="color:#66d9ef">print</span>(working_df<span style="color:#f92672">.</span>head())
</code></pre></div><pre><code>   Age Preferred Foot Height  Weight  Agility  Strength  Dribbling  Jumping  \
0   31           Left    5'7  159lbs     91.0      59.0       97.0     68.0   
1   33          Right    6'2  183lbs     87.0      79.0       88.0     95.0   
2   26          Right    5'9  150lbs     96.0      49.0       96.0     61.0   
3   27          Right    6'4  168lbs     60.0      64.0       18.0     67.0   
4   27          Right   5'11  154lbs     79.0      75.0       86.0     63.0   

   Marking  Interceptions Position  
0     33.0           22.0       RF  
1     28.0           29.0       ST  
2     27.0           36.0       LW  
3     15.0           30.0       GK  
4     68.0           61.0      RCM  
</code></pre>
<p>Now that we have a working data set, let&rsquo;s start processing the data. There are two basic types of transformations we can apply:</p>
<ul>
<li><strong>Encoding</strong>: for getting a numerical representation of categorical values (usally strings)</li>
<li><strong>Scaling</strong>: for normalizing continious values</li>
</ul>
<h2 id="encoding">Encoding</h2>
<p>Encoding is one of the easiest things to undesrtand, since at its core it is just as simple as assigning one unique numerical value to each unique categorical value. For example, on the <code>Position</code> column of the data set that would mean:</p>
<ul>
<li><code>CB -&gt; 0</code></li>
<li><code>CM -&gt; 1</code></li>
<li><code>GK -&gt; 2</code></li>
<li><code>LB -&gt; 3</code></li>
<li><code>ST -&gt; 4</code></li>
<li>&hellip;</li>
</ul>
<p>We can achieve this with the <code>LabelEncoder</code> class in the <code>preprocessing</code> module of Scikit learn.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#f92672">from</span> sklearn.preprocessing <span style="color:#f92672">import</span> LabelEncoder
<span style="color:#75715e"># create the encoder for the colum</span>
position_encoder <span style="color:#f92672">=</span> LabelEncoder()
<span style="color:#75715e"># learn the classes and assign a code to each</span>
position_encoder<span style="color:#f92672">.</span>fit(working_df[<span style="color:#e6db74">&#39;Position&#39;</span>])

<span style="color:#75715e"># get the encoded column</span>
encoded_position <span style="color:#f92672">=</span> position_encoder<span style="color:#f92672">.</span>transform(working_df[<span style="color:#e6db74">&#39;Position&#39;</span>])
encoded_position
</code></pre></div><pre><code>array([21, 26, 14, ..., 26, 24,  4])
</code></pre>
<p>For getting back the original classes from the numerical representations, we can use the <code>inverse_transform</code> method from the encoder.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">position_encoder<span style="color:#f92672">.</span>inverse_transform(encoded_position)
</code></pre></div><pre><code>array(['RF', 'ST', 'LW', ..., 'ST', 'RW', 'CM'], dtype=object)
</code></pre>
<h2 id="scaling">Scaling</h2>
<p>For continious values, there&rsquo;s no reason to transform them into numerical representations. How ever, a model can have some difficulties on learning patterns in the data if it has a very large range of values.</p>
<p>For example, a model could take some time learning patterns for values ranging from <code>0 to 255</code> (like the intensity of a pixel in an image), but it&rsquo;d take a very short time with values from <code>0 to 1</code>. Since a value of <code>125</code> in a range from <code>0 to 255</code> represents the sames as <code>0.5</code> in a range from <code>0 to 1</code>, we can change the scale of the first range in order to make it more efficient. This is what the <strong>scaling</strong> process does.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#f92672">from</span> sklearn.preprocessing <span style="color:#f92672">import</span> MinMaxScaler

<span style="color:#75715e"># There are many types of scalers</span>
strength_scaler <span style="color:#f92672">=</span> MinMaxScaler()
<span style="color:#75715e"># Note that the scalers receive a 2D array as input</span>
strength_scaler<span style="color:#f92672">.</span>fit(working_df[[<span style="color:#e6db74">&#39;Strength&#39;</span>]])
<span style="color:#75715e"># Get the scaled version</span>
scaled_strength <span style="color:#f92672">=</span> strength_scaler<span style="color:#f92672">.</span>transform(working_df[[<span style="color:#e6db74">&#39;Strength&#39;</span>]])
scaled_strength
</code></pre></div><pre><code>array([[0.525 ],
       [0.775 ],
       [0.4   ],
       ...,
       [0.1875],
       [0.3875],
       [0.5375]])
</code></pre>
<h2 id="finishing-the-pipeline">Finishing the pipeline</h2>
<p>How to store the transformed values depends on your preference and attributes of your data set. Since this case has a data set relatively small, we can create a copy of it with the transformed values.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#75715e"># New data frame</span>
clean_df <span style="color:#f92672">=</span> pd<span style="color:#f92672">.</span>DataFrame()

<span style="color:#75715e"># I will create a dictionary for storing all my encoders</span>
encoders <span style="color:#f92672">=</span> {
    <span style="color:#e6db74">&#39;Preferred Foot&#39;</span>: LabelEncoder(),
    <span style="color:#e6db74">&#39;Position&#39;</span>: LabelEncoder()
}

<span style="color:#75715e"># Encode all the categorical features</span>
<span style="color:#66d9ef">for</span> col, encoder <span style="color:#f92672">in</span> encoders<span style="color:#f92672">.</span>items():
    encoder<span style="color:#f92672">.</span>fit(working_df[col])
    clean_df[col] <span style="color:#f92672">=</span> encoder<span style="color:#f92672">.</span>transform(working_df[col])

scalers <span style="color:#f92672">=</span> {
    <span style="color:#e6db74">&#39;Agility&#39;</span>: MinMaxScaler(),
    <span style="color:#e6db74">&#39;Strength&#39;</span>: MinMaxScaler(),
    <span style="color:#e6db74">&#39;Dribbling&#39;</span>: MinMaxScaler(),
    <span style="color:#e6db74">&#39;Jumping&#39;</span>: MinMaxScaler(),
    <span style="color:#e6db74">&#39;Marking&#39;</span>: MinMaxScaler(),
    <span style="color:#e6db74">&#39;Interceptions&#39;</span>: MinMaxScaler()
}

<span style="color:#75715e"># Scale all the continous features</span>
<span style="color:#66d9ef">for</span> col, scaler <span style="color:#f92672">in</span> scalers<span style="color:#f92672">.</span>items():
    scaler<span style="color:#f92672">.</span>fit(working_df[[col]])
    clean_df[col] <span style="color:#f92672">=</span> scaler<span style="color:#f92672">.</span>transform(working_df[[col]])

<span style="color:#66d9ef">print</span>(clean_df<span style="color:#f92672">.</span>head())
</code></pre></div><pre><code>   Preferred Foot  Position   Agility  Strength  Dribbling  Jumping   Marking  \
0               0        21  0.939024    0.5250   1.000000   0.6625  0.329670   
1               1        26  0.890244    0.7750   0.903226   1.0000  0.274725   
2               1        14  1.000000    0.4000   0.989247   0.5750  0.263736   
3               1         5  0.560976    0.5875   0.150538   0.6500  0.131868   
4               1        19  0.792683    0.7250   0.881720   0.6000  0.714286   

   Interceptions  
0       0.213483  
1       0.292135  
2       0.370787  
3       0.303371  
4       0.651685  
</code></pre>
<p>This new <code>clean_df</code> looks really good for now, so I&rsquo;m gonna finish this part of the series by exporting it into a new file I can keep using later on.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">clean_df<span style="color:#f92672">.</span>to_csv(<span style="color:#e6db74">&#39;clean_data.csv&#39;</span>, index<span style="color:#f92672">=</span>None)
</code></pre></div><p>I will cover what we&rsquo;ll do with the <code>Height</code> and <code>Weight</code> columns in the next part of the series, as well as some more tricks to do with the stuff i covered in this one.</p>

    </div>
    
      
        <div class="pagination">
          <div class="pagination__title">
            <span class="pagination__title-h">Read other posts</span>
            <hr />
          </div>
          <div class="pagination__buttons">
            
              <span class="button previous">
                <a href="https://jinchuika.com/post/2-vs-code-remote/">
                  <span class="button__icon">←</span>
                  <span class="button__text">What is the new Visual Studio Code Remote feature and how to use it</span>
                </a>
              </span>
            
            
          </div>
        </div>
      
    


    
      
        

      
    

    </div>

  </div>
  
    <footer class="footer">
  <div class="footer__inner">
    
      <div class="copyright copyright--user">Luis Carlos Contreras</div>
    
  </div>
</footer>

<script src="https://jinchuika.com/assets/main.js"></script>
<script src="https://jinchuika.com/assets/prism.js"></script>
<script type="application/javascript">
    var doNotTrack = false;
    if (!doNotTrack) {
        (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
        (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
        m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
        })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
        ga('create', 'UA-60599533-1', 'auto');
        
        ga('send', 'pageview');
    }
</script>

  
</div>

</body>
</html>
