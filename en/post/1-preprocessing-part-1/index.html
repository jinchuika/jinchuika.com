<!DOCTYPE html>
<html lang="en">
<head>
  
    <script type="application/ld+json">
{
    "@context" : "http://schema.org",
    "@type" : "BlogPosting",
    "mainEntityOfPage": {
         "@type": "WebPage",
         "@id": "https://jinchuika.com"
    },
    "articleSection" : "post",
    "name" : "Preprocessing data for data science (Part 1)",
    "headline" : "Preprocessing data for data science (Part 1)",
    "description" : "A [study regarding data science jobs](https://visit.figure-eight.com/rs/416-ZBE-142/images/CrowdFlower_DataScienceReport_2016.pdf) showed that 60% of the time spent by data scientists consists only on cleaning and organizing data. So in order to make the most out of our time, my data science fellas, in this four-part series we&#39;ll se how to preprocess data like a boss, using the Pandas Python library and the preprocessing module from scikit-learn.",
    "inLanguage" : "en",
    "author" : "Luis Carlos Contreras",
    "creator" : "Luis Carlos Contreras",
    "publisher": "Jinchuika",
    "accountablePerson" : "",
    "copyrightHolder" : "Luis Carlos Contreras",
    "copyrightYear" : "2019",
    "datePublished": "2019-03-28 22:46:51 -0600 CST",
    "dateModified" : "2019-03-28 22:46:51 -0600 CST",
    "url" : "https://jinchuika.com/en/post/1-preprocessing-part-1/",
    "wordCount" : "1127",
    "keywords" : [ "Blog" ]
}
</script>

    <title>Preprocessing data for data science (Part 1) :: Jinchuika — Developer blog</title>
  
  <meta http-equiv="content-type" content="text/html; charset=utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1">
<meta name="description" content="A study regarding data science jobs showed that 60% of the time spent by data scientists consists only on cleaning and organizing data. So in order to make the most out of our time, my data science fellas, in this four-part series we&amp;rsquo;ll se how to preprocess data like a boss, using the Pandas Python library and the preprocessing module from scikit-learn.
Pretty much everything we do in an AI algorithm are matrix operations."/>
<meta name="keywords" content="blog,technology,programming,artificial intelligence,machine learning"/>
<meta name="robots" content="noodp"/>
<link rel="canonical" href="https://jinchuika.com/en/post/1-preprocessing-part-1/" />


<link rel="stylesheet" href="https://jinchuika.com/assets/style.css">


<link rel="stylesheet" href="https://jinchuika.com/style.css">


<link rel="apple-touch-icon-precomposed" sizes="144x144" href="https://jinchuika.com/img/apple-touch-icon-144-precomposed.png">
<link rel="shortcut icon" href="https://jinchuika.com/img/favicon.ico">


<meta name="twitter:card" content="summary" />
<meta name="twitter:title" content="Preprocessing data for data science (Part 1) :: Jinchuika — Developer blog" />
<meta name="twitter:description" content="A study regarding data science jobs showed that 60% of the time spent by data scientists consists only on cleaning and organizing data. So in order to make the most out of our time, my data science fellas, in this four-part series we&amp;rsquo;ll se how to preprocess data like a boss, using the Pandas Python library and the preprocessing module from scikit-learn.
Pretty much everything we do in an AI algorithm are matrix operations." />
<meta name="twitter:site" content="https://jinchuika.com" />
<meta name="twitter:creator" content="Luis Carlos Contreras" />
<meta name="twitter:image" content="https://jinchuika.com/en/post/1-preprocessing-part-1/cover.jpg">


<meta property="og:locale" content="en" />
<meta property="og:type" content="article" />
<meta property="og:title" content="Preprocessing data for data science (Part 1) :: Jinchuika — Developer blog">
<meta property="og:description" content="A study regarding data science jobs showed that 60% of the time spent by data scientists consists only on cleaning and organizing data. So in order to make the most out of our time, my data science fellas, in this four-part series we&amp;rsquo;ll se how to preprocess data like a boss, using the Pandas Python library and the preprocessing module from scikit-learn.
Pretty much everything we do in an AI algorithm are matrix operations." />
<meta property="og:url" content="https://jinchuika.com/en/post/1-preprocessing-part-1/" />
<meta property="og:site_name" content="Preprocessing data for data science (Part 1)" />
<meta property="og:image" content="https://jinchuika.com/en/post/1-preprocessing-part-1/cover.jpg">
<meta property="og:image:width" content="2048">
<meta property="og:image:height" content="1024">

<meta property="article:published_time" content="2019-03-28 22:46:51 -0600 CST" />







</head>
<body class="dark-theme">
<div class="container">
  <header class="header">
  <span class="header__inner">
    <a href="https://jinchuika.com/" class="logo" style="text-decoration: none;">
  
    <span class="logo__mark"><svg xmlns="http://www.w3.org/2000/svg" class="greater-icon" width="44" height="44" viewBox="0 0 44 44">
  <polyline fill="none" stroke="#000" stroke-width="2" points="15 8 29.729 22.382 15 35.367"/>
</svg>
</span>
    <span class="logo__text">Jinchuika</span>
    <span class="logo__cursor"></span>
  
</a>

    <span class="header__right">
      
        <nav class="menu">
  <ul class="menu__inner menu__inner--desktop">
    
      
        
          <li><a href="https://jinchuika.com/about">About</a></li>
        
      
        
          <li><a href="https://jinchuika.com/es">Español</a></li>
        
      
      
    
  </ul>

  <ul class="menu__inner menu__inner--mobile">
    
      
        <li><a href="https://jinchuika.com/about">About</a></li>
      
    
      
        <li><a href="https://jinchuika.com/es">Español</a></li>
      
    
  </ul>
</nav>

        <span class="menu-trigger">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
            <path d="M0 0h24v24H0z" fill="none"/>
            <path d="M3 18h18v-2H3v2zm0-5h18v-2H3v2zm0-7v2h18V6H3z"/>
          </svg>
        </span>
      
      <span class="theme-toggle">
        <svg class="theme-toggler" width="24" height="24" viewBox="0 0 48 48" fill="none" xmlns="http://www.w3.org/2000/svg">
  <path d="M22 41C32.4934 41 41 32.4934 41 22C41 11.5066 32.4934 3 22
  3C11.5066 3 3 11.5066 3 22C3 32.4934 11.5066 41 22 41ZM7 22C7
  13.7157 13.7157 7 22 7V37C13.7157 37 7 30.2843 7 22Z"/>
</svg>

      </span>
    </span>
  </span>
</header>


  <div class="content">
    
  <div class="post">
    <h2 class="post-title"><a href="https://jinchuika.com/en/post/1-preprocessing-part-1/">Preprocessing data for data science (Part 1)</a></h2>
    <div class="post-meta">
      
        <span class="post-date">
            2019-03-28
        </span>
      
      <span class="post-author">— Written by Luis Carlos Contreras</span>
      
        <span class="post-read-time">— 6 min read</span>
      
    </div>

    

    
      
        <img src="https://jinchuika.com/en/post/1-preprocessing-part-1/cover.jpg" class="post-cover" />
      
    

    <div class="post-content">
      

<p>A <a href="https://visit.figure-eight.com/rs/416-ZBE-142/images/CrowdFlower_DataScienceReport_2016.pdf">study regarding data science jobs</a> showed that 60% of the time spent by data scientists consists only on cleaning and organizing data. So in order to make the most out of our time, my data science fellas, in this four-part series we&rsquo;ll se how to preprocess data like a boss, using the Pandas Python library and the preprocessing module from scikit-learn.</p>

<p>Pretty much everything we do in an AI algorithm are matrix operations. That means that every value must be represented in a numerical format and, ideally, one that optimizes the operations performance. Given that most datasets come in a very nonoptimal format, we must apply certain transformations in order to obtain the most ideal format. This process is called <strong>preprocessing</strong>.</p>

<h2 id="start-of-the-cleaning-data-process">Start of the cleaning data process</h2>

<p>For this series of examples we&rsquo;ll be using <a href="https://www.kaggle.com/karangadiya/fifa19">this interesting dataset of FIFA 19 players</a>. This game allows players to create a custom character with different values for their stats like speed, weight, height, etc. We will create an algorithm for recommending the most ideal position (striker, central back, etc.) for that character based on those values and what we&rsquo;ve learned from the rest of the football player base.</p>

<blockquote>
<p>You can find all the code for this series in the <a href="https://github.com/jinchuika/preprocessing-tutorial/blob/master/part-1.ipynb">GitHub repo</a>.</p>
</blockquote>

<p>As always, we&rsquo;ll start by loading the data and do a basic exploration of it.</p>

<pre><code class="language-python">import pandas as pd
raw_df = pd.read_csv('data.csv')
# raw_df.info() # display all the columns and their data type
</code></pre>

<p>The very first thing to do is choosing what features could be useful for training the model. Let&rsquo;s start by discriminating what features definitely won&rsquo;t contribute and then choosing which ones could.</p>

<p>As rule of thumb, using unique non-numerical values is not useful since we want the model to generalize. So columns like <code>ID</code> and <code>Name</code> have to go. Features that are highly correlated to each other or are directly calculations don&rsquo;t need to be included twice. For example, if we store the birth date, we don&rsquo;t need to include the age since it is a result from the prior. In this case, <code>Overall</code> is the score resulting from the rest of the features, so there&rsquo;s no need to have it.</p>

<p>Knowing what features influence the outcome of the objective one is a complex task. For the sake of this post lenght, we&rsquo;ll arbitrarily pick some based on what we think impacts a player&rsquo;s skill. Once the features are selected, let&rsquo;s make a new data frame with only the colums we chose.</p>

<pre><code class="language-python"># it's useful to have the columns in a list you can modify easily
useful_columns = [
    'Age',
    'Preferred Foot',
    'Height',
    'Weight',
    'Agility',
    'Strength',
    'Dribbling',
    'Jumping',
    'Marking',
    'Interceptions',
    'Position', # I like to let my objective columns at the end
]
working_df = raw_df[useful_columns]
print(working_df.head())
</code></pre>

<pre><code>   Age Preferred Foot Height  Weight  Agility  Strength  Dribbling  Jumping  \
0   31           Left    5'7  159lbs     91.0      59.0       97.0     68.0   
1   33          Right    6'2  183lbs     87.0      79.0       88.0     95.0   
2   26          Right    5'9  150lbs     96.0      49.0       96.0     61.0   
3   27          Right    6'4  168lbs     60.0      64.0       18.0     67.0   
4   27          Right   5'11  154lbs     79.0      75.0       86.0     63.0   

   Marking  Interceptions Position  
0     33.0           22.0       RF  
1     28.0           29.0       ST  
2     27.0           36.0       LW  
3     15.0           30.0       GK  
4     68.0           61.0      RCM  
</code></pre>

<p>Now that we have a working data set, let&rsquo;s start processing the data. There are two basic types of transformations we can apply:</p>

<ul>
<li><strong>Encoding</strong>: for getting a numerical representation of categorical values (usally strings)</li>
<li><strong>Scaling</strong>: for normalizing continious values</li>
</ul>

<h2 id="encoding">Encoding</h2>

<p>Encoding is one of the easiest things to undesrtand, since at its core it is just as simple as assigning one unique numerical value to each unique categorical value. For example, on the <code>Position</code> column of the data set that would mean:</p>

<ul>
<li><code>CB -&gt; 0</code></li>
<li><code>CM -&gt; 1</code></li>
<li><code>GK -&gt; 2</code></li>
<li><code>LB -&gt; 3</code></li>
<li><code>ST -&gt; 4</code></li>
<li>&hellip;</li>
</ul>

<p>We can achieve this with the <code>LabelEncoder</code> class in the <code>preprocessing</code> module of Scikit learn.</p>

<pre><code class="language-python">from sklearn.preprocessing import LabelEncoder
# create the encoder for the colum
position_encoder = LabelEncoder()
# learn the classes and assign a code to each
position_encoder.fit(working_df['Position'])

# get the encoded column
encoded_position = position_encoder.transform(working_df['Position'])
encoded_position
</code></pre>

<pre><code>array([21, 26, 14, ..., 26, 24,  4])
</code></pre>

<p>For getting back the original classes from the numerical representations, we can use the <code>inverse_transform</code> method from the encoder.</p>

<pre><code class="language-python">position_encoder.inverse_transform(encoded_position)
</code></pre>

<pre><code>array(['RF', 'ST', 'LW', ..., 'ST', 'RW', 'CM'], dtype=object)
</code></pre>

<h2 id="scaling">Scaling</h2>

<p>For continious values, there&rsquo;s no reason to transform them into numerical representations. How ever, a model can have some difficulties on learning patterns in the data if it has a very large range of values.</p>

<p>For example, a model could take some time learning patterns for values ranging from <code>0 to 255</code> (like the intensity of a pixel in an image), but it&rsquo;d take a very short time with values from <code>0 to 1</code>. Since a value of <code>125</code> in a range from <code>0 to 255</code> represents the sames as <code>0.5</code> in a range from <code>0 to 1</code>, we can change the scale of the first range in order to make it more efficient. This is what the <strong>scaling</strong> process does.</p>

<pre><code class="language-python">from sklearn.preprocessing import MinMaxScaler

# There are many types of scalers
strength_scaler = MinMaxScaler()
# Note that the scalers receive a 2D array as input
strength_scaler.fit(working_df[['Strength']])
# Get the scaled version
scaled_strength = strength_scaler.transform(working_df[['Strength']])
scaled_strength
</code></pre>

<pre><code>array([[0.525 ],
       [0.775 ],
       [0.4   ],
       ...,
       [0.1875],
       [0.3875],
       [0.5375]])
</code></pre>

<h2 id="finishing-the-pipeline">Finishing the pipeline</h2>

<p>How to store the transformed values depends on your preference and attributes of your data set. Since this case has a data set relatively small, we can create a copy of it with the transformed values.</p>

<pre><code class="language-python"># New data frame
clean_df = pd.DataFrame()

# I will create a dictionary for storing all my encoders
encoders = {
    'Preferred Foot': LabelEncoder(),
    'Position': LabelEncoder()
}

# Encode all the categorical features
for col, encoder in encoders.items():
    encoder.fit(working_df[col])
    clean_df[col] = encoder.transform(working_df[col])

scalers = {
    'Agility': MinMaxScaler(),
    'Strength': MinMaxScaler(),
    'Dribbling': MinMaxScaler(),
    'Jumping': MinMaxScaler(),
    'Marking': MinMaxScaler(),
    'Interceptions': MinMaxScaler()
}

# Scale all the continous features
for col, scaler in scalers.items():
    scaler.fit(working_df[[col]])
    clean_df[col] = scaler.transform(working_df[[col]])

print(clean_df.head())
</code></pre>

<pre><code>   Preferred Foot  Position   Agility  Strength  Dribbling  Jumping   Marking  \
0               0        21  0.939024    0.5250   1.000000   0.6625  0.329670   
1               1        26  0.890244    0.7750   0.903226   1.0000  0.274725   
2               1        14  1.000000    0.4000   0.989247   0.5750  0.263736   
3               1         5  0.560976    0.5875   0.150538   0.6500  0.131868   
4               1        19  0.792683    0.7250   0.881720   0.6000  0.714286   

   Interceptions  
0       0.213483  
1       0.292135  
2       0.370787  
3       0.303371  
4       0.651685  
</code></pre>

<p>This new <code>clean_df</code> looks really good for now, so I&rsquo;m gonna finish this part of the series by exporting it into a new file I can keep using later on.</p>

<pre><code class="language-python">clean_df.to_csv('clean_data.csv', index=None)
</code></pre>

<p>I will cover what we&rsquo;ll do with the <code>Height</code> and <code>Weight</code> columns in the next part of the series, as well as some more tricks to do with the stuff i covered in this one.</p>

    </div>
    
    





<div id="sharing">

<a class="resp-sharing-button__link" href="https://facebook.com/sharer/sharer.php?u=https%3a%2f%2fjinchuika.com%2fen%2fpost%2f1-preprocessing-part-1%2f" target="_blank" rel="noopener" aria-label="Facebook">
  <div class="resp-sharing-button resp-sharing-button--facebook resp-sharing-button--medium"><div aria-hidden="true" class="resp-sharing-button__icon resp-sharing-button__icon--solid">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M18.77 7.46H14.5v-1.9c0-.9.6-1.1 1-1.1h3V.5h-4.33C10.24.5 9.5 3.44 9.5 5.32v2.15h-3v4h3v12h5v-12h3.85l.42-4z"/></svg></div>Facebook</div>
</a>


<a class="resp-sharing-button__link" href="https://twitter.com/intent/tweet/?text=Preprocessing%20data%20for%20data%20science%20%28Part%201%29&amp;url=https%3a%2f%2fjinchuika.com%2fen%2fpost%2f1-preprocessing-part-1%2f" target="_blank" rel="noopener" aria-label="Twitter">
  <div class="resp-sharing-button resp-sharing-button--twitter resp-sharing-button--medium"><div aria-hidden="true" class="resp-sharing-button__icon resp-sharing-button__icon--solid">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M23.44 4.83c-.8.37-1.5.38-2.22.02.93-.56.98-.96 1.32-2.02-.88.52-1.86.9-2.9 1.1-.82-.88-2-1.43-3.3-1.43-2.5 0-4.55 2.04-4.55 4.54 0 .36.03.7.1 1.04-3.77-.2-7.12-2-9.36-4.75-.4.67-.6 1.45-.6 2.3 0 1.56.8 2.95 2 3.77-.74-.03-1.44-.23-2.05-.57v.06c0 2.2 1.56 4.03 3.64 4.44-.67.2-1.37.2-2.06.08.58 1.8 2.26 3.12 4.25 3.16C5.78 18.1 3.37 18.74 1 18.46c2 1.3 4.4 2.04 6.97 2.04 8.35 0 12.92-6.92 12.92-12.93 0-.2 0-.4-.02-.6.9-.63 1.96-1.22 2.56-2.14z"/></svg></div>Twitter</div>
</a>


<a class="resp-sharing-button__link" href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https%3a%2f%2fjinchuika.com%2fen%2fpost%2f1-preprocessing-part-1%2f&amp;title=Preprocessing%20data%20for%20data%20science%20%28Part%201%29&amp;summary=A%20%5bstudy%20regarding%20data%20science%20jobs%5d%28https%3a%2f%2fvisit.figure-eight.com%2frs%2f416-ZBE-142%2fimages%2fCrowdFlower_DataScienceReport_2016.pdf%29%20showed%20that%2060%25%20of%20the%20time%20spent%20by%20data%20scientists%20consists%20only%20on%20cleaning%20and%20organizing%20data.%20So%20in%20order%20to%20make%20the%20most%20out%20of%20our%20time%2c%20my%20data%20science%20fellas%2c%20in%20this%20four-part%20series%20we%27ll%20se%20how%20to%20preprocess%20data%20like%20a%20boss%2c%20using%20the%20Pandas%20Python%20library%20and%20the%20preprocessing%20module%20from%20scikit-learn.&amp;source=https%3a%2f%2fjinchuika.com%2fen%2fpost%2f1-preprocessing-part-1%2f" target="_blank" rel="noopener" aria-label="">
  <div class="resp-sharing-button resp-sharing-button--linkedin resp-sharing-button--small"><div aria-hidden="true" class="resp-sharing-button__icon resp-sharing-button__icon--solid">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M6.5 21.5h-5v-13h5v13zM4 6.5C2.5 6.5 1.5 5.3 1.5 4s1-2.4 2.5-2.4c1.6 0 2.5 1 2.6 2.5 0 1.4-1 2.5-2.6 2.5zm11.5 6c-1 0-2 1-2 2v7h-5v-13h5V10s1.6-1.5 4-1.5c3 0 5 2.2 5 6.3v6.7h-5v-7c0-1-1-2-2-2z"/></svg>
    </div>
  </div>
</a>


<a class="resp-sharing-button__link" href="https://reddit.com/submit/?url=https%3a%2f%2fjinchuika.com%2fen%2fpost%2f1-preprocessing-part-1%2f&amp;resubmit=true&amp;title=Preprocessing%20data%20for%20data%20science%20%28Part%201%29." target="_blank" rel="noopener" aria-label="Reddit">
  <div class="resp-sharing-button resp-sharing-button--reddit resp-sharing-button--medium"><div aria-hidden="true" class="resp-sharing-button__icon resp-sharing-button__icon--solid">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M24 11.5c0-1.65-1.35-3-3-3-.96 0-1.86.48-2.42 1.24-1.64-1-3.75-1.64-6.07-1.72.08-1.1.4-3.05 1.52-3.7.72-.4 1.73-.24 3 .5C17.2 6.3 18.46 7.5 20 7.5c1.65 0 3-1.35 3-3s-1.35-3-3-3c-1.38 0-2.54.94-2.88 2.22-1.43-.72-2.64-.8-3.6-.25-1.64.94-1.95 3.47-2 4.55-2.33.08-4.45.7-6.1 1.72C4.86 8.98 3.96 8.5 3 8.5c-1.65 0-3 1.35-3 3 0 1.32.84 2.44 2.05 2.84-.03.22-.05.44-.05.66 0 3.86 4.5 7 10 7s10-3.14 10-7c0-.22-.02-.44-.05-.66 1.2-.4 2.05-1.54 2.05-2.84zM2.3 13.37C1.5 13.07 1 12.35 1 11.5c0-1.1.9-2 2-2 .64 0 1.22.32 1.6.82-1.1.85-1.92 1.9-2.3 3.05zm3.7.13c0-1.1.9-2 2-2s2 .9 2 2-.9 2-2 2-2-.9-2-2zm9.8 4.8c-1.08.63-2.42.96-3.8.96-1.4 0-2.74-.34-3.8-.95-.24-.13-.32-.44-.2-.68.15-.24.46-.32.7-.18 1.83 1.06 4.76 1.06 6.6 0 .23-.13.53-.05.67.2.14.23.06.54-.18.67zm.2-2.8c-1.1 0-2-.9-2-2s.9-2 2-2 2 .9 2 2-.9 2-2 2zm5.7-2.13c-.38-1.16-1.2-2.2-2.3-3.05.38-.5.97-.82 1.6-.82 1.1 0 2 .9 2 2 0 .84-.53 1.57-1.3 1.87z"/></svg></div>Reddit</div>
</a>


</div>


    <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<script>
  (adsbygoogle = window.adsbygoogle || []).push({
    google_ad_client: "ca-pub-7910880084570598",
    enable_page_level_ads: true
  });
</script>

    
<div id="disqus_thread"></div>
<script type="application/javascript">
    var disqus_config = function () {
    
    
    
    };
    (function() {
        if (["localhost", "127.0.0.1"].indexOf(window.location.hostname) != -1) {
            document.getElementById('disqus_thread').innerHTML = 'Disqus comments not available by default when the website is previewed locally.';
            return;
        }
        var d = document, s = d.createElement('script'); s.async = true;
        s.src = '//' + "jinchuika" + '.disqus.com/embed.js';
        s.setAttribute('data-timestamp', +new Date());
        (d.head || d.body).appendChild(s);
    })();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
<a href="https://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>
    </div>

  </div>

  
    <footer class="footer">
  <div class="footer__inner">
    
      <a href="https://jinchuika.com/" class="logo" style="text-decoration: none;">
  
    <span class="logo__mark"><svg xmlns="http://www.w3.org/2000/svg" class="greater-icon" width="44" height="44" viewBox="0 0 44 44">
  <polyline fill="none" stroke="#000" stroke-width="2" points="15 8 29.729 22.382 15 35.367"/>
</svg>
</span>
    <span class="logo__text">Jinchuika</span>
    <span class="logo__cursor"></span>
  
</a>

      <div class="copyright">
        <span>© 2019 Luis Carlos Contreras</span>
      </div>
    
  </div>
</footer>

<script type="application/javascript">
var doNotTrack = false;
if (!doNotTrack) {
	(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
	(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
	m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
	})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
	ga('create', 'UA-60599533-1', 'auto');
	
	ga('send', 'pageview');
}
</script>

<script src="https://jinchuika.com/assets/main.js"></script>
<script src="https://jinchuika.com/assets/prism.js"></script>

  
</div>

</body><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<script>
  (adsbygoogle = window.adsbygoogle || []).push({
    google_ad_client: "ca-pub-7910880084570598",
    enable_page_level_ads: true
  });
</script>
</html>
