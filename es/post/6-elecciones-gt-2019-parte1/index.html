<!DOCTYPE html>
<html lang="es">
<head>
  
    <script type="application/ld+json">
{
    "@context" : "http://schema.org",
    "@type" : "BlogPosting",
    "mainEntityOfPage": {
        "@type": "WebPage",
        "@id": "https:\/\/jinchuika.com"
    },
    "articleSection" : "post",
    "name" : "Cómo descargué todos los datos de las elecciones de mi país usando Python (y cómo puedes hacerlo tú)",
    "headline" : "Cómo descargué todos los datos de las elecciones de mi país usando Python (y cómo puedes hacerlo tú)",
    "description" : "Teniendo en cuenta que la página del Tribunal Supremo Electoral (TSE) no tenía ninguna medida de seguridad y que no confío mucho que digamos en el TSE, decidí descargar todos los datos para realizar mi propio análisis. En este post te explico rápidamente cómo lo hice utilizando Python.",
    "inLanguage" : "es",
    "author": {
        "@type": "Person",
        "name": "Luis Carlos Contreras"
    },
    "publisher": {
        "@type": "Organization",
        "name": "Luis Carlos Contreras",
        "logo": {
            "@type": "ImageObject",
            "url": "https:\/\/jinchuika.com\/img\/favicon.ico",
            "width": "80",
            "height": "80"
        }
    },
    "creator" : "Luis Carlos Contreras",
    "copyrightHolder" : "Luis Carlos Contreras",
    "copyrightYear" : "2019",
    "datePublished": "2019-06-22 23:59:16 -0600 CST",
    "dateModified" : "2019-06-22 23:59:16 -0600 CST",
    "url" : "https:\/\/jinchuika.com\/es\/post\/6-elecciones-gt-2019-parte1\/",
    "wordCount" : "1590",
    
    "image": {
        "@type": "ImageObject",
        "url": "https:\/\/jinchuika.com\/es\/post\/6-elecciones-gt-2019-parte1\/cover.png",
        "width": 800,
        "height": 600
    },
    
    "keywords" : [
    
    ]
}
</script>

    <title>Cómo descargué todos los datos de las elecciones de mi país usando Python (y cómo puedes hacerlo tú) :: Jinchuika — Blog de programación</title>
  
  <meta http-equiv="content-type" content="text/html; charset=utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1">
<meta name="description" content="Resumen por si no quieres leer todo y únicamente quieres ver cómo lo hice:
 Link al repositorio con mi código, donde adjunto una guía de instalación si tú quieres hacer lo mismo: Repo en GitHub. Un archivo JSON con todos los datos, por si tú quieres realizar tu propio análisis: Descargar. Un archivo en CSV con los resultados de las elecciones presidenciables en cada una de las 21099 mesas electorales: Descargar."/>
<meta name="keywords" content="blog,tecnología,programación,inteligencia artificial,machine learning"/>
<meta name="robots" content="noodp"/>
<link rel="canonical" href="https://jinchuika.com/es/post/6-elecciones-gt-2019-parte1/" />





<link rel="stylesheet" href="https://jinchuika.com/assets/style.css">


<link rel="stylesheet" href="https://jinchuika.com/style.css">


<link rel="apple-touch-icon-precomposed" sizes="144x144" href="https://jinchuika.com/img/apple-touch-icon-144-precomposed.png">
<link rel="shortcut icon" href="https://jinchuika.com/img/favicon.png">


<meta name="twitter:card" content="summary_large_image"/>
<meta name="twitter:image" content="https://jinchuika.com/es/post/6-elecciones-gt-2019-parte1/cover.png"/>
<meta name="twitter:title" content="Cómo descargué todos los datos de las elecciones de mi país usando Python (y cómo puedes hacerlo tú)"/>
<meta name="twitter:description" content="Teniendo en cuenta que la página del Tribunal Supremo Electoral (TSE) no tenía ninguna medida de seguridad y que no confío mucho que digamos en el TSE, decidí descargar todos los datos para realizar mi propio análisis. En este post te explico rápidamente cómo lo hice utilizando Python."/>



<meta property="og:title" content="Cómo descargué todos los datos de las elecciones de mi país usando Python (y cómo puedes hacerlo tú)" />
<meta property="og:description" content="Teniendo en cuenta que la página del Tribunal Supremo Electoral (TSE) no tenía ninguna medida de seguridad y que no confío mucho que digamos en el TSE, decidí descargar todos los datos para realizar mi propio análisis. En este post te explico rápidamente cómo lo hice utilizando Python." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://jinchuika.com/es/post/6-elecciones-gt-2019-parte1/" /><meta property="og:image" content="https://jinchuika.com/es/post/6-elecciones-gt-2019-parte1/cover.png"/><meta property="article:section" content="post" />
<meta property="article:published_time" content="2019-06-22T23:59:16-06:00" />
<meta property="article:modified_time" content="2019-06-22T23:59:16-06:00" /><meta property="og:site_name" content="Jinchuika" />







  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<script>
(adsbygoogle = window.adsbygoogle || []).push({
	google_ad_client: "ca-pub-7910880084570598",
	enable_page_level_ads: true
});
</script>
</head>
<body class="dark-theme">
<div class="container">
  <header class="header">
  <span class="header__inner">
    <a href="https://jinchuika.com/es" class="logo" style="text-decoration: none;">
  
    <span class="logo__mark"><svg xmlns="http://www.w3.org/2000/svg" class="greater-icon" viewBox="0 0 44 44">
  <path fill="none" d="M15 8l14.729 14.382L15 35.367"/>
</svg>
</span>
    <span class="logo__text">Jinchuika</span>
    <span class="logo__cursor"></span>
  
</a>

    <span class="header__right">
      
        <nav class="menu">
  <ul class="menu__inner menu__inner--desktop">
    
      
        
          <li><a href="about">Acerca de</a></li>
        
      
        
          <li><a href="https://jinchuika.com/en">English</a></li>
        
      
      
    
  </ul>

  <ul class="menu__inner menu__inner--mobile">
    
      
        <li><a href="about">Acerca de</a></li>
      
    
      
        <li><a href="https://jinchuika.com/en">English</a></li>
      
    
  </ul>
</nav>

        <span class="menu-trigger">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
            <path d="M0 0h24v24H0z" fill="none"/>
            <path d="M3 18h18v-2H3v2zm0-5h18v-2H3v2zm0-7v2h18V6H3z"/>
          </svg>
        </span>
      
      <span class="theme-toggle">
        <svg class="theme-toggler" width="24" height="24" viewBox="0 0 48 48" fill="none" xmlns="http://www.w3.org/2000/svg">
  <path d="M22 41C32.4934 41 41 32.4934 41 22C41 11.5066 32.4934 3 22
  3C11.5066 3 3 11.5066 3 22C3 32.4934 11.5066 41 22 41ZM7 22C7
  13.7157 13.7157 7 22 7V37C13.7157 37 7 30.2843 7 22Z"/>
</svg>

      </span>
    </span>
  </span>
</header>


  <div class="content">
    
  
  

  <div class="post">
    <h2 class="post-title"><a href="https://jinchuika.com/es/post/6-elecciones-gt-2019-parte1/">Cómo descargué todos los datos de las elecciones de mi país usando Python (y cómo puedes hacerlo tú)</a></h2>
    <div class="post-meta">
      
        <span class="post-date">
          2019-06-22
        </span>

        
          
        
      

      <span class="post-author">— Escrito por Luis Carlos Contreras</span>
      
        <span class="post-read-time">— 8 minutos</span>
      
    </div>

    

    
      
        <img src="https://jinchuika.com/es/post/6-elecciones-gt-2019-parte1/cover.png" class="post-cover" />
      
    

    <div class="post-content">
      <blockquote>
<p><em>Resumen por si no quieres leer todo y únicamente quieres ver cómo lo hice:</em></p>
<ul>
<li>Link al repositorio con mi código, donde adjunto una guía de instalación si tú quieres hacer lo mismo: <a href="https://github.com/jinchuika/tse-scraper"><strong>Repo en GitHub</strong></a>.</li>
<li>Un archivo JSON con todos los datos, por si tú quieres realizar tu propio análisis: <a href="resultados.zip"><strong>Descargar</strong></a>.</li>
<li>Un archivo en CSV con los resultados de las elecciones presidenciables en cada una de las 21099 mesas electorales: <a href="resultados_csv.zip"><strong>Descargar</strong></a>.</li>
</ul>
</blockquote>
<p>El pasado 16 de junio se <em>celebraron</em> las <a href="https://es.wikipedia.org/wiki/Elecciones_generales_de_Guatemala_de_2019">elecciones generales en mi país</a>. En cuanto empezó el conteo de votos <a href="https://twitter.com/i/moments/1142781711228579840">expresé mi molestia en twitter</a> sobre la pésima calidad de la página creada por el Tribunal Supremo Electoral (TSE) para consultar los resultados. Teniendo en cuenta que su página no tenía ninguna medida de seguridad y que no confío mucho que digamos en el TSE, decidí descargar todos los datos para realizar mi propio análisis. En este post te explico rápidamente cómo lo hice.</p>
<p>Empecemos por analizar cómo funciona <a href="https://resultados2019.tse.org.gt">la página de resultados</a>. Una simple inspección en la página en la sección &ldquo;Red&rdquo; te mostrará que está desarrollada en PHP. Cada vez que realizas una consulta para ver un tipo de resultado se envía una petición al backend con los parámetros de la solicitud. Estos parámetros incluyen:</p>
<ul>
<li><code>d</code>: <strong>Departamento</strong>: el código del departamento (estado o región en otros países) a consultar. Como se muestra en la imagen, el departamento número <code>0</code> indica que se debe ignorar este filtro.</li>
<li><code>m</code>: <strong>Municipio</strong>: el código del municipio (ciudad en otros países). El filtro utiliza el <code>0</code> en la misma forma que el departamento.</li>
<li><code>te</code>: <strong>Tipo de elección</strong>: el tipo de elección con el código <code>1</code> indica que es la elección para presidente, el <code>2</code> la de diputados (congresistas) por listado nacional, el <code>3</code> diputados departamentales, el <code>4</code> la de alcaldes municipales y el <code>5</code> la de diputados al Parlamento Centroamericano. (Si te causa alguna inquietud que en Guatemala se elijan tantos cargos públicos al mismo tiempo, déjame compartir que a mí también).</li>
<li><code>vista</code>: <strong>Tipo de vista</strong>: existen dos tipos de consultas que se pueden realizar. La primera es de resultados (<code>RESULTADO</code>), donde puedes ver el resumen de la cantidad de votos que obtuvo cada candidato. La segunda (<code>MESA</code>) es mucho más interesante. Permite consultar el detalle de cada mesa electoral ingresando el identificador de ésta.</li>
<li><code>token</code>: Un token de <em>seguridad</em> que permite garantizar el origen de la solicitud. Tendré mucho más de qué hablar sobre este token dentro de poco.</li>
</ul>

  <img src="1.png"  alt="Solicitud realizada a la página de consulta de TSE"  class="center"  style="border-radius: 8px;"  />


<p>El TSE tuvo a bien ordenar los resultados en formato JSON sin ningún tipo de encriptación (si lo hicieron por simplicidad, por contribuir a los datos abiertos o por falta de capacidad, lo dejo a tu discreción). Revisé la estructura de la respuesta del servidor para una solicitud al tipo de vista <code>MESA</code> y encontré que era muy fácil de entender:</p>
<ul>
<li>Existe un listado que contiene los resultados de cada tipo de elección.</li>
<li>Debido a que hay tipos de elecciones con una cantidad variable de candidatos (por ejemplo, un partido político pudo haber postulado a alguien para presidente pero no para alcalde de una ciudad específica), cada tipo de elección tiene un listado de registros con los votos estructurados como muestra la imagen próxima.</li>
<li>Cada tipo de elección contiene un resumen de los datos de su mesa electoral para ese tipo en específico. Este resumen incluye datos como la cantidad de votos válidos, nulos e inválidos, un link a una foto del acta sobre los resultados de la mesa, la cantidad de papeletas disponibles y&hellip; <strong>¡¿un campo que indica si los datos del conteo de votos cuadran o no?!</strong>.</li>
</ul>

  <img src="2.png"  alt="Estructura de los votos en la página del TSE"  class="center"  style="border-radius: 8px;"  />


<p>Me llamó mucho la atención que existiera este campo. ¿Por qué habríamos de suponer que los votos no cuadren? En ese momento supe que tenía que descargar todos los datos y comparar yo mismo que fueran reales. Imaginé que sería fácil hacer algo así utilizando Python, pero seguramente el token de seguridad estaría ligado a una sesión específica o tendría un tiempo de expiración muy corto. En cualquier caso, nada costaría probar para saber qué tipo de seguridad utiliza el token. Utilicé el paquete de Python <code>requests</code> para hacer solicitudes de forma fácil a cualquier URL.</p>

  <img src="3.png"  alt="Solicitud a la página del TSE usando Python"  class="center"  style="border-radius: 8px;"  />


<p>Y ¡vaya sorpresa! El token no valida prácticamente nada. Esperé un tiempo para volver a utilizarlo y seguía funcionando. Incluso probé el mismo token en otra máquina y aún tenía éxito. Esto da luz verde para generar un script que descargue y organice todos los datos.</p>
<h3 id="creación-del-script-de-python">Creación del script de Python</h3>
<p>Empecé por utilizar un ambiente virtual de Python manejado por Pipenv. Si no tienes experiencia en ello, su página web es una muy buena referencia del uso. No necesitaremos ninguna otra dependencia externa para descargar los datos.</p>
<p>Como mostré anteriormente, realizar una solicitud es bastante simple:</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#75715e"># importar el paquete</span>
<span style="color:#f92672">import</span> requests
<span style="color:#75715e"># crear el objeto de la solicitud</span>
r <span style="color:#f92672">=</span> requests<span style="color:#f92672">.</span>get(url)
<span style="color:#75715e"># convertir el json de la respuesta en una estructura de Python como listas o diccionarios</span>
r<span style="color:#f92672">.</span>json()
</code></pre></div><p>Utilizando este código, es bastante sencillo crear una función que me permita obtener los datos de una mesa específica:</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">url <span style="color:#f92672">=</span> <span style="color:#e6db74">&#39;https://resultados2019.tse.org.gt/201901/api.php&#39;</span>
token <span style="color:#f92672">=</span> <span style="color:#e6db74">&#39;&#39;</span>

<span style="color:#66d9ef">def</span> <span style="color:#a6e22e">query_api</span>(num):
    params <span style="color:#f92672">=</span> {<span style="color:#e6db74">&#39;token&#39;</span>: token, <span style="color:#e6db74">&#39;mesa&#39;</span>: num, <span style="color:#e6db74">&#39;vista&#39;</span>: <span style="color:#e6db74">&#39;MESA&#39;</span>}
    query_url <span style="color:#f92672">=</span> f<span style="color:#e6db74">&#39;{url}?token={params[&#34;token&#34;]}&amp;mesa={params[&#34;mesa&#34;]}&amp;vista={params[&#34;vista&#34;]}&#39;</span>
    r <span style="color:#f92672">=</span> requests<span style="color:#f92672">.</span>get(url<span style="color:#f92672">=</span>query_url, data<span style="color:#f92672">=</span>params)
    data <span style="color:#f92672">=</span> r<span style="color:#f92672">.</span>json()
</code></pre></div><p>Algo que he aprendido tras varios años de hacer web scraping, es que no puedes confiar en que una solicitud larga se mantenga abierta por mucho tiempo. Debes guardar tu trabajo seguido por si hay algún problema con el servidor a donde te conectes. Por esta razón, voy a generar un archivo único por cada mesa. Si el proceso falla en la mesa número 15321, al menos tendré el resto almacenado. Para ello, vamos a exportar los datos con:</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#f92672">import</span> json

<span style="color:#66d9ef">with</span> open(f<span style="color:#e6db74">&#39;carpeta_data/{num}.json&#39;</span>, <span style="color:#e6db74">&#39;w&#39;</span>, encoding<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;utf-8&#39;</span>) <span style="color:#66d9ef">as</span> outfile:
    json<span style="color:#f92672">.</span>dump(data, outfile, ensure_ascii<span style="color:#f92672">=</span>False, indent<span style="color:#f92672">=</span><span style="color:#ae81ff">2</span>)
</code></pre></div><p>Podríamos dejarlo hasta ahí, pero en serio no confío mucho que digamos en mi gobierno, por lo que decidí que también sería bueno descargar las imágenes contenidas en la URL de cada registro. Para ello, vamos a utilizar:</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#f92672">import</span> shutil
<span style="color:#75715e"># recorremos cada uno de los tipos de elección en esa mesa</span>
<span style="color:#66d9ef">for</span> i, te <span style="color:#f92672">in</span> enumerate(data[<span style="color:#e6db74">&#39;TE&#39;</span>]):
    folder <span style="color:#f92672">=</span> f<span style="color:#e6db74">&#39;carpeta_imagenes/{i}&#39;</span>
    <span style="color:#75715e"># obtener el tipo de extensión de la imagen</span>
    extension <span style="color:#f92672">=</span> te[<span style="color:#e6db74">&#39;IMGSRC&#39;</span>]<span style="color:#f92672">.</span>split(<span style="color:#e6db74">&#39;.&#39;</span>)[<span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>]
    <span style="color:#75715e"># consultar la URL de la imagen</span>
    response <span style="color:#f92672">=</span> requests<span style="color:#f92672">.</span>get(te[<span style="color:#e6db74">&#39;IMGSRC&#39;</span>], stream<span style="color:#f92672">=</span>True)
    <span style="color:#66d9ef">with</span> open(f<span style="color:#e6db74">&#39;carpeta_imagenes/{i}/{num}.{extension}&#39;</span>, <span style="color:#e6db74">&#39;wb&#39;</span>) <span style="color:#66d9ef">as</span> out_file:
        shutil<span style="color:#f92672">.</span>copyfileobj(response<span style="color:#f92672">.</span>raw, out_file)
    <span style="color:#66d9ef">del</span> response
</code></pre></div><p>Por lo tanto, el método final queda de la siguiente manera:</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">url <span style="color:#f92672">=</span> <span style="color:#e6db74">&#39;https://resultados2019.tse.org.gt/201901/api.php&#39;</span>

<span style="color:#75715e"># obtén tu propio token desde la página del TSE</span>
token <span style="color:#f92672">=</span> <span style="color:#e6db74">&#39;&#39;</span>
<span style="color:#75715e"># la carpeta donde desees guardar los datos</span>
output_folder_raw <span style="color:#f92672">=</span> <span style="color:#e6db74">&#39;&#39;</span>
<span style="color:#75715e"># la carpeta donde quieras guardar las imágenes</span>
<span style="color:#75715e"># dentro de esta carpeta debes generar otras 5 llamadas 0, 1, 2, 3, y 4</span>
output_folder_images <span style="color:#f92672">=</span> <span style="color:#e6db74">&#39;&#39;</span>


<span style="color:#66d9ef">def</span> <span style="color:#a6e22e">query_api</span>(num):
    params <span style="color:#f92672">=</span> {<span style="color:#e6db74">&#39;token&#39;</span>: token, <span style="color:#e6db74">&#39;mesa&#39;</span>: num, <span style="color:#e6db74">&#39;vista&#39;</span>: <span style="color:#e6db74">&#39;MESA&#39;</span>}
    query_url <span style="color:#f92672">=</span> f<span style="color:#e6db74">&#39;{url}?token={params[&#34;token&#34;]}&amp;mesa={params[&#34;mesa&#34;]}&amp;vista={params[&#34;vista&#34;]}&#39;</span>
    <span style="color:#66d9ef">print</span>(f<span style="color:#e6db74">&#39;Consulting... : {num}&#39;</span>)
    r <span style="color:#f92672">=</span> requests<span style="color:#f92672">.</span>get(url<span style="color:#f92672">=</span>query_url, data<span style="color:#f92672">=</span>params)
    data <span style="color:#f92672">=</span> r<span style="color:#f92672">.</span>json()
    <span style="color:#66d9ef">with</span> open(f<span style="color:#e6db74">&#39;{output_folder_raw}/{num}.json&#39;</span>, <span style="color:#e6db74">&#39;w&#39;</span>, encoding<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;utf-8&#39;</span>) <span style="color:#66d9ef">as</span> outfile:
        json<span style="color:#f92672">.</span>dump(data, outfile, ensure_ascii<span style="color:#f92672">=</span>False, indent<span style="color:#f92672">=</span><span style="color:#ae81ff">2</span>)
    <span style="color:#66d9ef">try</span>:
        <span style="color:#66d9ef">for</span> i, te <span style="color:#f92672">in</span> enumerate(data[<span style="color:#e6db74">&#39;TE&#39;</span>]):
            folder <span style="color:#f92672">=</span> f<span style="color:#e6db74">&#39;{output_folder_images}/{i}&#39;</span>
            extension <span style="color:#f92672">=</span> te[<span style="color:#e6db74">&#39;IMGSRC&#39;</span>]<span style="color:#f92672">.</span>split(<span style="color:#e6db74">&#39;.&#39;</span>)[<span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>]
            <span style="color:#75715e"># puse esta validacion para consultar unicamente si el archivo no existe</span>
            <span style="color:#66d9ef">if</span> f<span style="color:#e6db74">&#39;{num}.{extension}&#39;</span> <span style="color:#f92672">not</span> <span style="color:#f92672">in</span> os<span style="color:#f92672">.</span>listdir(folder):
                response <span style="color:#f92672">=</span> requests<span style="color:#f92672">.</span>get(te[<span style="color:#e6db74">&#39;IMGSRC&#39;</span>], stream<span style="color:#f92672">=</span>True)
                <span style="color:#66d9ef">with</span> open(f<span style="color:#e6db74">&#39;{output_folder_images}/{i}/{num}.{extension}&#39;</span>, <span style="color:#e6db74">&#39;wb&#39;</span>) <span style="color:#66d9ef">as</span> out_file:
                    shutil<span style="color:#f92672">.</span>copyfileobj(response<span style="color:#f92672">.</span>raw, out_file)
                <span style="color:#66d9ef">del</span> response
    <span style="color:#66d9ef">except</span> <span style="color:#a6e22e">KeyError</span>:
        <span style="color:#66d9ef">pass</span>
    <span style="color:#66d9ef">print</span>(f<span style="color:#e6db74">&#39;Done with {num}&#39;</span>)
</code></pre></div><p>Hasta aquí todo bastante bien, podemos ejecutar esta función dentro de un ciclo para realizar la consulta de todas las mesas. Sin embargo, este proceso tardaría mucho tiempo puesto que se debería esperar a que cada mesa descargue sus datos para empezar con la siguiente. Para evitar este inconveniente utilizaremos la siempre útil ejecución en paralelo. Ya que explicar cómo funciona este método es algo que supera el alcance de este post, simplemente te explicaré cómo funcionan las partes clave:</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#75715e"># la función que contiene la secuencia de órdenes asíncronas</span>


async <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">main</span>():
    starting <span style="color:#f92672">=</span> <span style="color:#ae81ff">1</span>
    ending <span style="color:#f92672">=</span> <span style="color:#ae81ff">21100</span>
    <span style="color:#75715e"># aquí le decimos que queremos utilizar 8 hilos al mismo tiempo</span>
    <span style="color:#66d9ef">with</span> concurrent<span style="color:#f92672">.</span>futures<span style="color:#f92672">.</span>ThreadPoolExecutor(max_workers<span style="color:#f92672">=</span><span style="color:#ae81ff">8</span>) <span style="color:#66d9ef">as</span> executor:
        <span style="color:#75715e"># obtenemos el ciclo de eventos de nuestro gestor asíncrono</span>
        loop <span style="color:#f92672">=</span> asyncio<span style="color:#f92672">.</span>get_event_loop()
        <span style="color:#75715e"># parámetros para la función a ejecutar en el ciclo de eventos</span>
        futures <span style="color:#f92672">=</span> [
            loop<span style="color:#f92672">.</span>run_in_executor(
                executor,
                query_api,
                i
            )
            <span style="color:#66d9ef">for</span> i <span style="color:#f92672">in</span> range(starting, ending)
        ]
        <span style="color:#75715e"># ejecutamos la función en un ciclo sin esperar al resultado de cada repetición para continuar</span>
        <span style="color:#66d9ef">for</span> response <span style="color:#f92672">in</span> await asyncio<span style="color:#f92672">.</span>gather(<span style="color:#f92672">*</span>futures):
            <span style="color:#66d9ef">pass</span>


loop <span style="color:#f92672">=</span> asyncio<span style="color:#f92672">.</span>get_event_loop()
loop<span style="color:#f92672">.</span>run_until_complete(main())
</code></pre></div><p>¡Y eso es todo! Ahora podemos ejecutar nuestro archivo desde la línea de comandos y esperar&hellip; Esperar un buen rato. Curiosamente, de vez en cuando alguna de las solicitudes puede llegar a ser rechazada, por lo que tendrás que esperar a que termine y ejecutar de nuevo el comando. Encontré una solución simple a no tener que hacer solicitudes dos veces, que puedes consultar en <a href="https://github.com/jinchuika/tse-scraper/blob/master/scraper.py">el archivo completo en GitHub</a>. Esta solución utiliza el paquete NumPy, por lo quizas quieras revisar la descripción del repositorio antes de ejecutarlo.</p>
<h2 id="resultados-finales">Resultados finales</h2>

  <img src="4.png"  alt="Resultados finales"  class="center"  style="border-radius: 8px;"  />


<p>Después de correr el script con 1500 registros me di cuenta de que mi humilde computadora no sería suficiente para soportar la carga de trabajo, por lo que decidí adquirir un servidor básico en la nube donde pudiera ejecutarlo con confianza. Después de unas dos horas de trabajo, los resultados fueron:</p>
<ul>
<li>41 GB de fotos descargadas</li>
<li>105037 fotos de actas descargadas</li>
<li>247 MB de archivos JSON</li>
<li>21099 archivos JSON con los resultados de las papeletas</li>
</ul>
<p>Estoy trabajando en el análisis de datos utilizando Pandas y Bokeh para crear una visualización útil sobre los datos. Así que no olvides seguirme en <a href="https://twitter.com/chui_k">Twitter</a> para saber cuando esté lista.</p>
<hr>
<p><em>Gracias a <a href="https://twitter.com/tansalaxar">David</a>, <a href="https://github.com/Zeuhan">Hans</a>, <a href="https://github.com/Csanchezz">Carlos</a> y Kwai por ayudarme a terminar este proyecto y editar este post.</em></p>

    </div>
    
      
        <div class="pagination">
          <div class="pagination__title">
            <span class="pagination__title-h">Leer otros post</span>
            <hr />
          </div>
          <div class="pagination__buttons">
            
              <span class="button previous">
                <a href="https://jinchuika.com/es/post/7-elecciones-gt-2019-parte2/">
                  <span class="button__icon">←</span>
                  <span class="button__text">Cómo procesar los datos de las elecciones generales utilizando Python</span>
                </a>
              </span>
            
            
              <span class="button next">
                <a href="https://jinchuika.com/es/post/5-por-que-python/">
                  <span class="button__text">Por qué usar Python para desarrollar inteligencia artificial</span>
                  <span class="button__icon">→</span>
                </a>
              </span>
            
          </div>
        </div>
      
    


    
      
        

      
    

    </div>

  </div>
  
    <footer class="footer">
  <div class="footer__inner">
    
      <div class="copyright copyright--user">Luis Carlos Contreras</div>
    
  </div>
</footer>

<script src="https://jinchuika.com/assets/main.js"></script>
<script src="https://jinchuika.com/assets/prism.js"></script>
<script type="application/javascript">
    var doNotTrack = false;
    if (!doNotTrack) {
        (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
        (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
        m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
        })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
        ga('create', 'UA-60599533-1', 'auto');
        
        ga('send', 'pageview');
    }
</script>

  
</div>

</body>
</html>
